{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137c42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from core.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c55d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.7091018557548523\n",
      "epoch: 1, loss: 0.7091018557548523\n",
      "epoch: 2, loss: 0.5209541320800781\n",
      "epoch: 3, loss: 0.3634335994720459\n",
      "epoch: 4, loss: 0.23542895913124084\n",
      "epoch: 5, loss: 0.14115245640277863\n",
      "epoch: 6, loss: 0.0861542746424675\n",
      "epoch: 7, loss: 0.05306215211749077\n",
      "epoch: 8, loss: 0.033054251223802567\n",
      "epoch: 9, loss: 0.020747782662510872\n",
      "epoch: 10, loss: 0.013131925836205482\n",
      "epoch: 11, loss: 0.008316180668771267\n",
      "epoch: 12, loss: 0.005297856405377388\n",
      "epoch: 13, loss: 0.003367597935721278\n",
      "epoch: 14, loss: 0.0021573614794760942\n",
      "epoch: 15, loss: 0.0013735126703977585\n",
      "epoch: 16, loss: 0.0008814406464807689\n",
      "epoch: 17, loss: 0.000561053748242557\n",
      "epoch: 18, loss: 0.0003613209701143205\n",
      "epoch: 19, loss: 0.0002377033233642578\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data = torch.randn(100, 5).to(device)\n",
    "target = torch.ones((100, 1)).to(device)\n",
    "model = nn.Linear(5, 1).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.12)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device, max_grad_norm=1)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    loss = trainer.train_step(data, target)\n",
    "    print(f'epoch: {epoch}, loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fdb647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.0105857849121094\n",
      "epoch: 1, loss: 1.0105857849121094\n",
      "epoch: 2, loss: 0.7771100401878357\n",
      "epoch: 3, loss: 0.5750308036804199\n",
      "epoch: 4, loss: 0.4037010371685028\n",
      "epoch: 5, loss: 0.2631549537181854\n",
      "epoch: 6, loss: 0.1530485451221466\n",
      "epoch: 7, loss: 0.08730300515890121\n",
      "epoch: 8, loss: 0.050091180950403214\n",
      "epoch: 9, loss: 0.028876103460788727\n",
      "epoch: 10, loss: 0.016778169199824333\n",
      "epoch: 11, loss: 0.00979549903422594\n",
      "epoch: 12, loss: 0.005743596237152815\n",
      "epoch: 13, loss: 0.003388204611837864\n",
      "epoch: 14, loss: 0.0020145464222878218\n",
      "epoch: 15, loss: 0.0011958170216530561\n",
      "epoch: 16, loss: 0.0007236742530949414\n",
      "epoch: 17, loss: 0.0004403138009365648\n",
      "epoch: 18, loss: 0.000265095237409696\n",
      "epoch: 19, loss: 0.00016272543871309608\n"
     ]
    }
   ],
   "source": [
    "from core.utils.seed import set_seed\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "data = torch.randn(100, 5).to(device)\n",
    "target = torch.ones((100, 1)).to(device)\n",
    "model = nn.Linear(5, 1).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.12)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device, max_grad_norm=1)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    loss = trainer.train_step(data, target)\n",
    "    print(f'epoch: {epoch}, loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1d5d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>e:\\coding\\Algorithmic Trading\\notebooks\\01_pytorch_basics\\wandb\\offline-run-20260224_131257-m5pkc2zc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.0105857849121094\n",
      "epoch: 1, loss: 1.0105857849121094\n",
      "epoch: 2, loss: 0.7771100401878357\n",
      "epoch: 3, loss: 0.5750308036804199\n",
      "epoch: 4, loss: 0.4037010371685028\n",
      "epoch: 5, loss: 0.2631549537181854\n",
      "epoch: 6, loss: 0.1530485451221466\n",
      "epoch: 7, loss: 0.08730300515890121\n",
      "epoch: 8, loss: 0.050091180950403214\n",
      "epoch: 9, loss: 0.028876103460788727\n",
      "epoch: 10, loss: 0.016778169199824333\n",
      "epoch: 11, loss: 0.00979549903422594\n",
      "epoch: 12, loss: 0.005743596237152815\n",
      "epoch: 13, loss: 0.003388204611837864\n",
      "epoch: 14, loss: 0.0020145464222878218\n",
      "epoch: 15, loss: 0.0011958170216530561\n",
      "epoch: 16, loss: 0.0007236742530949414\n",
      "epoch: 17, loss: 0.0004403138009365648\n",
      "epoch: 18, loss: 0.000265095237409696\n",
      "epoch: 19, loss: 0.00016272543871309608\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>██▆▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_loss</td><td>0.00016</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync e:\\coding\\Algorithmic Trading\\notebooks\\01_pytorch_basics\\wandb\\offline-run-20260224_131257-m5pkc2zc<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20260224_131257-m5pkc2zc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from core.training.trainer import Trainer\n",
    "from core.utils.seed import set_seed\n",
    "\n",
    "\n",
    "with open('../../configs/experiment_01.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "entity = config['experiment']['entity']\n",
    "project = config['experiment']['project']\n",
    "seed = config['experiment']['seed']\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=entity,\n",
    "    project=project,\n",
    "    config=config,\n",
    "    mode='offline'\n",
    ")\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "lr = config['hyperparameters']['learning_rate']\n",
    "epochs = config['hyperparameters']['epochs']\n",
    "max_grad_norm = config['hyperparameters']['max_grad_norm']\n",
    "input_dim = config['architecture']['input_dim']\n",
    "output_dim = config['architecture']['output_dim']\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data = torch.randn(100, input_dim).to(device)\n",
    "target = torch.ones((100, output_dim)).to(device)\n",
    "model = nn.Linear(input_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device, max_grad_norm)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = trainer.train_step(data, target)\n",
    "    wandb.log({\"train_loss\": loss, \"epoch\": epoch})\n",
    "    print(f'epoch: {epoch}, loss: {loss}') \n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
