{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf4c1c1",
   "metadata": {},
   "source": [
    "# Part A: Leaf Node and In-place Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8b75e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a leaf Variable that requires grad is being used in an in-place operation.\n",
      "grad: tensor([3., 2.])\n",
      "w: tensor([2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "w = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "output = w[0] * w[1]\n",
    "\n",
    "try:\n",
    "    w += 1.0  \n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "output.backward()\n",
    "\n",
    "print(f\"grad: {w.grad}\")\n",
    "print(f\"w: {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6d341f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingv\\AppData\\Local\\Temp\\ipykernel_11428\\575195260.py:9: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(w.grad)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "output = w[0] * w[1]\n",
    "\n",
    "w = w + 1.0\n",
    "\n",
    "output.backward()\n",
    "\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4277380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: tensor([3., 2.])\n",
      "Updated w: tensor([3., 4.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "output = w[0] * w[1]\n",
    "\n",
    "output.backward()\n",
    "print(\"Gradient:\", w.grad)  \n",
    "\n",
    "with torch.no_grad():\n",
    "    w += 1.0          \n",
    "\n",
    "print(\"Updated w:\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ffca7",
   "metadata": {},
   "source": [
    "# Part B: (mini-project) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "319570a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b98dc628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       close\n",
      "timestamp                   \n",
      "2017-08-17 04:00:00  4261.48\n",
      "2017-08-17 04:01:00  4261.48\n",
      "2017-08-17 04:02:00  4280.56\n",
      "2017-08-17 04:03:00  4261.48\n",
      "2017-08-17 04:04:00  4261.48\n",
      "2017-08-17 04:05:00  4261.48\n",
      "2017-08-17 04:06:00  4261.48\n",
      "2017-08-17 04:07:00  4261.48\n",
      "2017-08-17 04:08:00  4261.48\n",
      "2017-08-17 04:09:00  4261.48\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"../data/BTCUSDT.csv\", sep='|', nrows=10, header=None, usecols=[0,4],\n",
    "                       names=['timestamp', 'close'])\n",
    "data_df['timestamp'] = pd.to_datetime(data_df['timestamp'], unit='s')\n",
    "data_df.set_index('timestamp', inplace=True)\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "46234385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4261.4800],\n",
       "         [4261.4800],\n",
       "         [4280.5601],\n",
       "         [4261.4800],\n",
       "         [4261.4800],\n",
       "         [4261.4800],\n",
       "         [4261.4800],\n",
       "         [4261.4800],\n",
       "         [4261.4800],\n",
       "         [4261.4800]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.tensor(data_df.values, dtype=torch.float32)\n",
    "data_tensor, data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1ed4f49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: tensor([[2.2278e+08]], grad_fn=<PowBackward0>)\n",
      "Epoch: 1, loss: tensor([[90247440.]], grad_fn=<PowBackward0>)\n",
      "Epoch: 2, loss: tensor([[36558688.]], grad_fn=<PowBackward0>)\n",
      "Epoch: 3, loss: tensor([[14809699.]], grad_fn=<PowBackward0>)\n",
      "Epoch: 4, loss: tensor([[5999316.]], grad_fn=<PowBackward0>)\n",
      "Epoch: 5, loss: tensor([[2430288.5000]], grad_fn=<PowBackward0>)\n",
      "Epoch: 6, loss: tensor([[984495.6250]], grad_fn=<PowBackward0>)\n",
      "Epoch: 7, loss: tensor([[398813.5312]], grad_fn=<PowBackward0>)\n",
      "Epoch: 8, loss: tensor([[161557.4844]], grad_fn=<PowBackward0>)\n",
      "Epoch: 9, loss: tensor([[65445.5312]], grad_fn=<PowBackward0>)\n",
      "Epoch: 10, loss: tensor([[26511.8066]], grad_fn=<PowBackward0>)\n",
      "Epoch: 11, loss: tensor([[10739.8105]], grad_fn=<PowBackward0>)\n",
      "Epoch: 12, loss: tensor([[4350.6519]], grad_fn=<PowBackward0>)\n",
      "Epoch: 13, loss: tensor([[1762.4418]], grad_fn=<PowBackward0>)\n",
      "Epoch: 14, loss: tensor([[713.9960]], grad_fn=<PowBackward0>)\n",
      "Epoch: 15, loss: tensor([[289.2408]], grad_fn=<PowBackward0>)\n",
      "Epoch: 16, loss: tensor([[117.1637]], grad_fn=<PowBackward0>)\n",
      "Epoch: 17, loss: tensor([[47.4673]], grad_fn=<PowBackward0>)\n",
      "Epoch: 18, loss: tensor([[19.2240]], grad_fn=<PowBackward0>)\n",
      "Epoch: 19, loss: tensor([[7.7884]], grad_fn=<PowBackward0>)\n",
      "weights after training :  tensor([[ 0.4454],\n",
      "        [-1.1899],\n",
      "        [-0.1046],\n",
      "        [ 0.4106],\n",
      "        [ 1.2777],\n",
      "        [-0.4209],\n",
      "        [-1.0624],\n",
      "        [ 0.0790],\n",
      "        [ 0.1281],\n",
      "        [ 0.4615]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn_like(data_tensor, requires_grad=True)\n",
    "\n",
    "target = torch.tensor(100)\n",
    "\n",
    "learning_rate = 1e-9\n",
    "\n",
    "for i in range(20):\n",
    "    y = w.T @ data_tensor\n",
    "\n",
    "    loss = (y - target) ** 2\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    print(f\"Epoch: {i}, loss: {loss}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    w.grad.zero_()\n",
    "\n",
    "print(\"weights after training : \", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e89a78",
   "metadata": {},
   "source": [
    "# Part C: Advanced Indexing and Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "20aa7131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.2615e+03, 4.2615e+03, 4.2615e+03, 4.2615e+03, 1.7752e+00],\n",
      "        [4.2615e+03, 4.2615e+03, 4.2615e+03, 4.2615e+03, 0.0000e+00],\n",
      "        [4.2806e+03, 4.2806e+03, 4.2806e+03, 4.2806e+03, 2.6107e-01],\n",
      "        [4.2615e+03, 4.2615e+03, 4.2615e+03, 4.2615e+03, 1.2008e-02],\n",
      "        [4.2615e+03, 4.2615e+03, 4.2615e+03, 4.2615e+03, 1.4080e-01]])\n"
     ]
    }
   ],
   "source": [
    "data_df2 = pd.read_csv(\"../data/BTCUSDT.csv\", sep='|', nrows=100, header=None, usecols=[1, 2, 3, 4, 5],\n",
    "                       names=['open', 'high', 'low', 'close', 'volume'])\n",
    "data_tensor2 = torch.tensor(data_df2.values, dtype=torch.float32)\n",
    "print(data_tensor2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "dc50ff69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high = data_tensor2[:, 1]\n",
    "low = data_tensor2[:, 2]\n",
    "close = data_tensor2[:, 3]\n",
    "\n",
    "typical_price = (high + low + close) / 3\n",
    "typical_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3536c9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = data_tensor2[:, -1]\n",
    "min_vol = torch.min(volume)\n",
    "vol_normalized = (volume - min_vol) / (torch.max(volume) - min_vol)\n",
    "vol_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d6cd3d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bullish = data_tensor2[data_tensor2[:, 3] > data_tensor2[:, 0]]\n",
    "bullish.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55a2a6",
   "metadata": {},
   "source": [
    "# Part D: Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "e8aa152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LinearRewardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, 5))\n",
    "        self.register_buffer('profit_target', torch.tensor([[100.0]]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x @ self.weights.T \n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1bd79dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6422face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 30717424.0\n",
      "epoch: 1, loss: 6992160.0\n",
      "epoch: 2, loss: 1591631.75\n",
      "epoch: 3, loss: 362323.0\n",
      "epoch: 4, loss: 82498.171875\n",
      "epoch: 5, loss: 18802.2265625\n",
      "epoch: 6, loss: 4303.37451171875\n",
      "epoch: 7, loss: 1002.9652099609375\n",
      "epoch: 8, loss: 251.72073364257812\n",
      "epoch: 9, loss: 80.70658874511719\n",
      "epoch: 10, loss: 41.77900314331055\n",
      "epoch: 11, loss: 32.914188385009766\n",
      "epoch: 12, loss: 30.89735221862793\n",
      "epoch: 13, loss: 30.437728881835938\n",
      "epoch: 14, loss: 30.3337345123291\n",
      "epoch: 15, loss: 30.309885025024414\n",
      "epoch: 16, loss: 30.304393768310547\n",
      "epoch: 17, loss: 30.303050994873047\n",
      "epoch: 18, loss: 30.302913665771484\n",
      "epoch: 19, loss: 30.30229949951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kingv\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "data_tensor2 = data_tensor2.to(device)\n",
    "model = LinearRewardNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(data_tensor2)\n",
    "    loss = criterion(y_pred, model.profit_target)\n",
    "    print(f\"epoch: {epoch}, loss: {loss}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b77e95ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[101.2942],\n",
      "        [ 99.0562],\n",
      "        [ 99.8284],\n",
      "        [ 99.0713],\n",
      "        [ 99.2336]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(data_tensor2)\n",
    "\n",
    "    print(predict[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
